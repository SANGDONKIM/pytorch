{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch geometric.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMSSa7Njm9Q4igVvsSRfrqs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SANGDONKIM/pytorch_d2l/blob/main/pytorch_geometric.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NM3j1czNSUWO"
      },
      "source": [
        "import numpy as np \n",
        "import torch \n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import colors \n",
        "plt.rcParams.update({\"font.size\" : 16})"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9h1ljdaSSUTL"
      },
      "source": [
        "input_dim = 1\n",
        "output_dim = 1\n",
        "\n",
        "A = 2*np.random.rand(output_dim, input_dim) - 1\n",
        "b = 2*np.random.rand(output_dim) - 1\n",
        "\n",
        "true_model = lambda x: A@x + b # lambda 매개변수 : 결과 \n",
        "\n"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyx46YQEcl_3"
      },
      "source": [
        "n_train = 1000\n",
        "noise_level = 0.04\n",
        "\n",
        "# Generate a random set of n_train samples\n",
        "X_train = np.random.rand(n_train, input_dim)\n",
        "y_train = np.array([true_model(x) for x in X_train])\n",
        "\n",
        "# Add some noise\n",
        "y_train += noise_level * np.random.standard_normal(size=y_train.shape)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "id": "0mZeaPA4SUN-",
        "outputId": "620ec7ea-f961-4f9d-935f-064404eff016"
      },
      "source": [
        "\n",
        "if input_dim == output_dim == 1:\n",
        "    fig = plt.figure()\n",
        "    fig.clf()\n",
        "    ax = fig.gca()\n",
        "    ax.plot(X_train, y_train, '.')\n",
        "    ax.grid(True)\n",
        "    ax.set_xlabel('X_train')\n",
        "    ax.set_ylabel('y_train')"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fiB_Cf1diXQ"
      },
      "source": [
        "# pytorch dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1S7IgBhRSUJA",
        "outputId": "822efe8c-94ec-4e59-a392-179afc45bad2"
      },
      "source": [
        "#!git clone https://github.com/SANGDONKIM/PytorchGeometricTutorial.git\n"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'PytorchGeometricTutorial'...\n",
            "remote: Enumerating objects: 246, done.\u001b[K\n",
            "remote: Counting objects: 100% (246/246), done.\u001b[K\n",
            "remote: Compressing objects: 100% (193/193), done.\u001b[K\n",
            "remote: Total 246 (delta 84), reused 202 (delta 44), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (246/246), 17.43 MiB | 43.00 KiB/s, done.\n",
            "Resolving deltas: 100% (84/84), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubJ238WcSUEn"
      },
      "source": [
        "class VectorialDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, input_data, output_data):\n",
        "        super(VectorialDataset, self).__init__()\n",
        "        self.input_data = torch.tensor(input_data.astype('f'))\n",
        "        self.output_data = torch.tensor(output_data.astype('f'))\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.input_data.shape[0]\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist() # list로 변환 \n",
        "        sample = (self.input_data[idx, :], \n",
        "                  self.output_data[idx, :])  \n",
        "        return sample \n",
        "    "
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daX2HjsckqBs",
        "outputId": "96842d98-4d1f-4174-a134-a53317174cd0"
      },
      "source": [
        "training_set = VectorialDataset(input_data = X_train, output_data = y_train)\n",
        "len(training_dataset)\n",
        "training_set[10:12]"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.1112],\n",
              "         [0.8843]]), tensor([[0.5139],\n",
              "         [0.7791]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imHjUBxGsO8T"
      },
      "source": [
        "# DataLoader\n",
        "- class 데이터셋을 만들면 DataLoader 사용 가능 \n",
        "- DataLoader는 dataset, batch size 를 input으로 받음 \n",
        "- batch size는 통상적으로 2의 배수를 사용함(64, 128 등등) \n",
        "- shuffle = T는 epoch마다 데이터셋을 섞어서 데이터가 학습되는 순서를 바꿈 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9WKoPlXoT49"
      },
      "source": [
        "batch_size = 120 \n",
        "train_loader = torch.utils.data.DataLoader(training_set, \n",
        "                                           batch_size = batch_size, \n",
        "                                           shuffle = True)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zchZhSWpff_",
        "outputId": "52f8bd4b-30b4-4375-bc66-d0fa4822dc61"
      },
      "source": [
        "# enumerate \n",
        "#반복문 사용 시 몇 번째 반복문인지 확인이 필요할 수 있음. 이때 사용함\n",
        "#인덱스 번호와 컬렉션의 원소를 tuple형태로 반환\n",
        "t = [1, 5, 7, 33, 39, 52]\n",
        "for p in enumerate(t):\n",
        "    print(p)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0, 1)\n",
            "(1, 5)\n",
            "(2, 7)\n",
            "(3, 33)\n",
            "(4, 39)\n",
            "(5, 52)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vIMJwJPo2zd",
        "outputId": "fefc13c6-9763-4df3-b50d-dbbc6c944dcf"
      },
      "source": [
        "#for idx, batch in enumerate(train_loader):\n",
        "#    print(idx)\n",
        "#    print(batch)\n",
        "\n",
        "\n",
        "for idx, batch in enumerate(train_loader):\n",
        "    print('Batch n. %2d: input size = %s, output size = %s' % (idx+1, batch[0].shape, batch[1].shape))\n"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch n.  1: input size = torch.Size([120, 1]), output size = torch.Size([120, 1])\n",
            "Batch n.  2: input size = torch.Size([120, 1]), output size = torch.Size([120, 1])\n",
            "Batch n.  3: input size = torch.Size([120, 1]), output size = torch.Size([120, 1])\n",
            "Batch n.  4: input size = torch.Size([120, 1]), output size = torch.Size([120, 1])\n",
            "Batch n.  5: input size = torch.Size([120, 1]), output size = torch.Size([120, 1])\n",
            "Batch n.  6: input size = torch.Size([120, 1]), output size = torch.Size([120, 1])\n",
            "Batch n.  7: input size = torch.Size([120, 1]), output size = torch.Size([120, 1])\n",
            "Batch n.  8: input size = torch.Size([120, 1]), output size = torch.Size([120, 1])\n",
            "Batch n.  9: input size = torch.Size([40, 1]), output size = torch.Size([40, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wY-wb5f6q6hU"
      },
      "source": [
        "# Shuffle = True 의 역할 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHM2Pf19p6vH",
        "outputId": "acb999e8-dd3f-4307-9fe5-f5d3e405709f"
      },
      "source": [
        "first_batch = []\n",
        "\n",
        "for epoch in range(2): \n",
        "    for idx, batch in enumerate(train_loader):\n",
        "        if idx == 0: \n",
        "            first_batch.append(batch)\n",
        "\n",
        "np.c_[X_train[:batch_size], first_batch[0][0], first_batch[1][0].numpy()]            "
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([120, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgRc2pRMx-Q0",
        "outputId": "144c3f63-5580-4cec-ae93-d1f021fd3552"
      },
      "source": [
        "batch_size = 120 \n",
        "train_loader = torch.utils.data.DataLoader(training_set, \n",
        "                                           batch_size = batch_size, \n",
        "                                           shuffle = False)\n",
        "\n",
        "first_batch = []\n",
        "\n",
        "for epoch in range(2): \n",
        "    for idx, batch in enumerate(train_loader):\n",
        "        if idx == 0: \n",
        "            first_batch.append(batch)\n",
        "\n",
        "np.c_[X_train[:batch_size], first_batch[0][0], first_batch[1][0].numpy()]            \n"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.23841376, 0.23841377, 0.23841377],\n",
              "       [0.13490346, 0.13490346, 0.13490346],\n",
              "       [0.88534117, 0.88534117, 0.88534117],\n",
              "       [0.85279145, 0.85279143, 0.85279143],\n",
              "       [0.14624195, 0.14624195, 0.14624195],\n",
              "       [0.57107503, 0.57107502, 0.57107502],\n",
              "       [0.10218975, 0.10218975, 0.10218975],\n",
              "       [0.97984139, 0.97984141, 0.97984141],\n",
              "       [0.69634786, 0.69634783, 0.69634783],\n",
              "       [0.87036444, 0.87036443, 0.87036443],\n",
              "       [0.11118421, 0.11118421, 0.11118421],\n",
              "       [0.88425221, 0.88425219, 0.88425219],\n",
              "       [0.00131947, 0.00131947, 0.00131947],\n",
              "       [0.45408662, 0.4540866 , 0.4540866 ],\n",
              "       [0.35117371, 0.3511737 , 0.3511737 ],\n",
              "       [0.79371864, 0.79371864, 0.79371864],\n",
              "       [0.59713784, 0.59713787, 0.59713787],\n",
              "       [0.72960531, 0.72960532, 0.72960532],\n",
              "       [0.73131809, 0.73131812, 0.73131812],\n",
              "       [0.40862168, 0.40862167, 0.40862167],\n",
              "       [0.92590793, 0.92590791, 0.92590791],\n",
              "       [0.8127235 , 0.81272352, 0.81272352],\n",
              "       [0.15155614, 0.15155615, 0.15155615],\n",
              "       [0.4834016 , 0.4834016 , 0.4834016 ],\n",
              "       [0.15730817, 0.15730818, 0.15730818],\n",
              "       [0.63371916, 0.63371915, 0.63371915],\n",
              "       [0.50502555, 0.50502557, 0.50502557],\n",
              "       [0.11459986, 0.11459986, 0.11459986],\n",
              "       [0.81485376, 0.81485379, 0.81485379],\n",
              "       [0.09246963, 0.09246963, 0.09246963],\n",
              "       [0.78814818, 0.78814816, 0.78814816],\n",
              "       [0.4871898 , 0.4871898 , 0.4871898 ],\n",
              "       [0.8601529 , 0.8601529 , 0.8601529 ],\n",
              "       [0.01813022, 0.01813022, 0.01813022],\n",
              "       [0.95164842, 0.95164841, 0.95164841],\n",
              "       [0.99532839, 0.99532837, 0.99532837],\n",
              "       [0.17991184, 0.17991184, 0.17991184],\n",
              "       [0.83966271, 0.83966273, 0.83966273],\n",
              "       [0.32574303, 0.32574302, 0.32574302],\n",
              "       [0.0872469 , 0.08724689, 0.08724689],\n",
              "       [0.74816369, 0.7481637 , 0.7481637 ],\n",
              "       [0.45843188, 0.45843187, 0.45843187],\n",
              "       [0.88427037, 0.88427037, 0.88427037],\n",
              "       [0.46053265, 0.46053267, 0.46053267],\n",
              "       [0.30828194, 0.30828196, 0.30828196],\n",
              "       [0.59369052, 0.59369051, 0.59369051],\n",
              "       [0.84042782, 0.84042782, 0.84042782],\n",
              "       [0.92584854, 0.92584854, 0.92584854],\n",
              "       [0.1937894 , 0.19378941, 0.19378941],\n",
              "       [0.59818866, 0.59818864, 0.59818864],\n",
              "       [0.83660474, 0.83660471, 0.83660471],\n",
              "       [0.54149613, 0.54149616, 0.54149616],\n",
              "       [0.41333365, 0.41333365, 0.41333365],\n",
              "       [0.39247399, 0.392474  , 0.392474  ],\n",
              "       [0.93826791, 0.93826789, 0.93826789],\n",
              "       [0.79355686, 0.79355687, 0.79355687],\n",
              "       [0.93016286, 0.93016285, 0.93016285],\n",
              "       [0.16656402, 0.16656402, 0.16656402],\n",
              "       [0.6631896 , 0.66318959, 0.66318959],\n",
              "       [0.33399405, 0.33399406, 0.33399406],\n",
              "       [0.66500775, 0.66500777, 0.66500777],\n",
              "       [0.17563475, 0.17563476, 0.17563476],\n",
              "       [0.99246579, 0.99246579, 0.99246579],\n",
              "       [0.54620718, 0.54620719, 0.54620719],\n",
              "       [0.96461794, 0.96461791, 0.96461791],\n",
              "       [0.15157149, 0.15157148, 0.15157148],\n",
              "       [0.48344531, 0.48344532, 0.48344532],\n",
              "       [0.24364138, 0.24364138, 0.24364138],\n",
              "       [0.0642402 , 0.06424019, 0.06424019],\n",
              "       [0.16518052, 0.16518052, 0.16518052],\n",
              "       [0.92356452, 0.92356449, 0.92356449],\n",
              "       [0.28803083, 0.28803083, 0.28803083],\n",
              "       [0.56134313, 0.56134313, 0.56134313],\n",
              "       [0.93035489, 0.93035489, 0.93035489],\n",
              "       [0.04414033, 0.04414033, 0.04414033],\n",
              "       [0.70034156, 0.70034158, 0.70034158],\n",
              "       [0.67395136, 0.67395139, 0.67395139],\n",
              "       [0.53276088, 0.53276086, 0.53276086],\n",
              "       [0.65785233, 0.65785235, 0.65785235],\n",
              "       [0.03817469, 0.03817469, 0.03817469],\n",
              "       [0.92955126, 0.92955124, 0.92955124],\n",
              "       [0.970279  , 0.97027898, 0.97027898],\n",
              "       [0.97427096, 0.97427094, 0.97427094],\n",
              "       [0.47398403, 0.47398403, 0.47398403],\n",
              "       [0.32470956, 0.32470956, 0.32470956],\n",
              "       [0.907678  , 0.90767801, 0.90767801],\n",
              "       [0.63926894, 0.63926893, 0.63926893],\n",
              "       [0.22552399, 0.22552399, 0.22552399],\n",
              "       [0.56115538, 0.56115538, 0.56115538],\n",
              "       [0.70206385, 0.70206386, 0.70206386],\n",
              "       [0.69268784, 0.69268781, 0.69268781],\n",
              "       [0.74661224, 0.74661225, 0.74661225],\n",
              "       [0.6353188 , 0.63531882, 0.63531882],\n",
              "       [0.99551757, 0.99551755, 0.99551755],\n",
              "       [0.79856593, 0.79856592, 0.79856592],\n",
              "       [0.56684042, 0.56684041, 0.56684041],\n",
              "       [0.88135611, 0.88135612, 0.88135612],\n",
              "       [0.93006828, 0.93006825, 0.93006825],\n",
              "       [0.88544375, 0.88544375, 0.88544375],\n",
              "       [0.88490458, 0.88490456, 0.88490456],\n",
              "       [0.04937514, 0.04937514, 0.04937514],\n",
              "       [0.28808343, 0.28808343, 0.28808343],\n",
              "       [0.15084586, 0.15084586, 0.15084586],\n",
              "       [0.93793989, 0.93793988, 0.93793988],\n",
              "       [0.90824889, 0.9082489 , 0.9082489 ],\n",
              "       [0.01867029, 0.01867029, 0.01867029],\n",
              "       [0.94505217, 0.94505215, 0.94505215],\n",
              "       [0.60529908, 0.60529906, 0.60529906],\n",
              "       [0.17046346, 0.17046346, 0.17046346],\n",
              "       [0.42827652, 0.42827651, 0.42827651],\n",
              "       [0.40878469, 0.40878469, 0.40878469],\n",
              "       [0.46469753, 0.46469754, 0.46469754],\n",
              "       [0.27066281, 0.27066281, 0.27066281],\n",
              "       [0.42963551, 0.42963549, 0.42963549],\n",
              "       [0.26376297, 0.26376298, 0.26376298],\n",
              "       [0.07355401, 0.073554  , 0.073554  ],\n",
              "       [0.03940027, 0.03940027, 0.03940027],\n",
              "       [0.01619316, 0.01619316, 0.01619316],\n",
              "       [0.83307367, 0.83307368, 0.83307368],\n",
              "       [0.11800218, 0.11800218, 0.11800218]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PmVVs5wSTvh"
      },
      "source": [
        "import torch.nn as nn\n",
        "class LinearModel(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(LinearModel, self).__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "        self.linear = nn.Linear(self.input_dim, self.output_dim, bias=True) # 사전에 구현되어 있는 AX + b 모델  \n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear(x)\n",
        "        return out\n",
        "    \n",
        "    def reset(self):\n",
        "        self.linear.reset_parameters()\n"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEjH3M1G1nLL",
        "outputId": "07c44ab9-e3fb-492e-f5b6-aea93e02b24b"
      },
      "source": [
        "model = LinearModel(input_dim, output_dim)\n",
        "print(model)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LinearModel(\n",
            "  (linear): Linear(in_features=1, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCxnXZce2En8",
        "outputId": "7d2e6d8f-001b-45e4-cde8-70aa66d00e8e"
      },
      "source": [
        "list(model.parameters()) # A, b "
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[0.5249]], requires_grad=True), Parameter containing:\n",
              " tensor([-0.3280], requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKEXfQZg2kpJ",
        "outputId": "07da0323-10fc-464e-9952-c7f3258294cd"
      },
      "source": [
        "model.linear.weight\n",
        "model.linear.bias"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([-0.3280], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2axazOD2_A4"
      },
      "source": [
        "# Forward method "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxROfQUx2kzf",
        "outputId": "901625ef-36b2-464e-8f1b-5873548893c0"
      },
      "source": [
        "x = torch.randn(5, input_dim)\n",
        "print(x)\n",
        "model.forward(x)"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.7007],\n",
            "        [ 1.5302],\n",
            "        [-0.5661],\n",
            "        [ 1.2851],\n",
            "        [-0.4641]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0399],\n",
              "        [ 0.4753],\n",
              "        [-0.6251],\n",
              "        [ 0.3466],\n",
              "        [-0.5716]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZH3roKA3Jk4",
        "outputId": "48d44bea-2a0f-4ad8-c51c-22d590aa4b3d"
      },
      "source": [
        "[model.linear.weight @ xx + model.linear.bias for xx in x]"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([0.0399], grad_fn=<AddBackward0>),\n",
              " tensor([0.4753], grad_fn=<AddBackward0>),\n",
              " tensor([-0.6251], grad_fn=<AddBackward0>),\n",
              " tensor([0.3466], grad_fn=<AddBackward0>),\n",
              " tensor([-0.5716], grad_fn=<AddBackward0>)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4GPN9PG3y4D"
      },
      "source": [
        "# Loss "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J73_LAwv2k8x",
        "outputId": "1506b4e5-5928-4476-c361-76ae364a44d1"
      },
      "source": [
        "import torch.nn as nn \n",
        "loss_fun = nn.MSELoss(reduction = \"mean\")\n",
        "\n",
        "x = torch.tensor(np.array([1, 2, 1]).astype('f'))\n",
        "z = torch.tensor(np.array([0, 0, 0]).astype('f'))\n",
        "\n",
        "loss_fun(x, z)\n"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lllFgMwA7s5o"
      },
      "source": [
        "x = torch.randn(1, input_dim)\n",
        "y = torch.randn(1, output_dim)\n",
        "\n",
        "model.zero_grad()\n",
        "loss = loss_fun(model.forward(x), y)\n",
        "loss.backward()\n"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SZAUC3N8VBN",
        "outputId": "da9ad5be-cc30-4c84-a76b-80010d367d0a"
      },
      "source": [
        "if input_dim == output_dim == 1: \n",
        "    print(model.linear.weight.grad)\n",
        "    print(2*x*(model.linear.weight*x+model.linear.bias-y))\n",
        "\n",
        "    print(model.linear.bias.grad)\n",
        "    print(2*(model.linear.weight*x + model.linear.bias - y))\n",
        "    "
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1.6275]])\n",
            "tensor([[1.6275]], grad_fn=<MulBackward0>)\n",
            "tensor([1.7127])\n",
            "tensor([[1.7127]], grad_fn=<MulBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srZl6ygZ92es",
        "outputId": "c1a9ecc3-ca66-463a-e873-f5fe8c25a690"
      },
      "source": [
        "lr = 0.1 \n",
        "weight_decay = 5e-4\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = lr, weight_decay = weight_decay)\n",
        "\n",
        "n_epochs = 100\n",
        "\n",
        "train_hist = {}\n",
        "train_hist['loss'] = []\n",
        "\n",
        "if input_dim == output_dim == 1: \n",
        "    train_hist[\"weight\"] = []\n",
        "    train_hist[\"bias\"] = []\n",
        "\n",
        "# initialize training \n",
        "model.reset()\n",
        "model.train()\n",
        "\n",
        "for epoch in range(n_epoch):\n",
        "    for idx, batch in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        loss = loss_fun(model.forward(batch[0]), batch[1])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_hist['loss'].append(loss.item())\n",
        "        if input_dim == output_dim == 1:\n",
        "            train_hist['weight'].append(model.linear.weight.item())\n",
        "            train_hist['bias'].append(model.linear.bias.item())\n",
        "\n",
        "        print('[Epoch %4d/%4d] [Batch %4d/%4d] Loss: % 2.2e' % (epoch + 1, n_epochs, idx + 1, len(train_loader), loss.item()))"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Epoch    1/ 100] [Batch    1/   9] Loss:  2.69e+00\n",
            "[Epoch    1/ 100] [Batch    2/   9] Loss:  2.00e+00\n",
            "[Epoch    1/ 100] [Batch    3/   9] Loss:  1.60e+00\n",
            "[Epoch    1/ 100] [Batch    4/   9] Loss:  1.22e+00\n",
            "[Epoch    1/ 100] [Batch    5/   9] Loss:  9.73e-01\n",
            "[Epoch    1/ 100] [Batch    6/   9] Loss:  6.93e-01\n",
            "[Epoch    1/ 100] [Batch    7/   9] Loss:  4.92e-01\n",
            "[Epoch    1/ 100] [Batch    8/   9] Loss:  3.23e-01\n",
            "[Epoch    1/ 100] [Batch    9/   9] Loss:  1.53e-01\n",
            "[Epoch    2/ 100] [Batch    1/   9] Loss:  1.03e-01\n",
            "[Epoch    2/ 100] [Batch    2/   9] Loss:  3.30e-02\n",
            "[Epoch    2/ 100] [Batch    3/   9] Loss:  6.90e-03\n",
            "[Epoch    2/ 100] [Batch    4/   9] Loss:  5.31e-03\n",
            "[Epoch    2/ 100] [Batch    5/   9] Loss:  1.92e-02\n",
            "[Epoch    2/ 100] [Batch    6/   9] Loss:  4.83e-02\n",
            "[Epoch    2/ 100] [Batch    7/   9] Loss:  7.89e-02\n",
            "[Epoch    2/ 100] [Batch    8/   9] Loss:  1.08e-01\n",
            "[Epoch    2/ 100] [Batch    9/   9] Loss:  1.37e-01\n",
            "[Epoch    3/ 100] [Batch    1/   9] Loss:  1.62e-01\n",
            "[Epoch    3/ 100] [Batch    2/   9] Loss:  1.71e-01\n",
            "[Epoch    3/ 100] [Batch    3/   9] Loss:  1.73e-01\n",
            "[Epoch    3/ 100] [Batch    4/   9] Loss:  1.72e-01\n",
            "[Epoch    3/ 100] [Batch    5/   9] Loss:  1.58e-01\n",
            "[Epoch    3/ 100] [Batch    6/   9] Loss:  1.46e-01\n",
            "[Epoch    3/ 100] [Batch    7/   9] Loss:  1.24e-01\n",
            "[Epoch    3/ 100] [Batch    8/   9] Loss:  9.79e-02\n",
            "[Epoch    3/ 100] [Batch    9/   9] Loss:  7.77e-02\n",
            "[Epoch    4/ 100] [Batch    1/   9] Loss:  5.59e-02\n",
            "[Epoch    4/ 100] [Batch    2/   9] Loss:  3.74e-02\n",
            "[Epoch    4/ 100] [Batch    3/   9] Loss:  2.21e-02\n",
            "[Epoch    4/ 100] [Batch    4/   9] Loss:  1.31e-02\n",
            "[Epoch    4/ 100] [Batch    5/   9] Loss:  5.50e-03\n",
            "[Epoch    4/ 100] [Batch    6/   9] Loss:  3.63e-03\n",
            "[Epoch    4/ 100] [Batch    7/   9] Loss:  3.79e-03\n",
            "[Epoch    4/ 100] [Batch    8/   9] Loss:  6.35e-03\n",
            "[Epoch    4/ 100] [Batch    9/   9] Loss:  7.08e-03\n",
            "[Epoch    5/ 100] [Batch    1/   9] Loss:  1.67e-02\n",
            "[Epoch    5/ 100] [Batch    2/   9] Loss:  1.78e-02\n",
            "[Epoch    5/ 100] [Batch    3/   9] Loss:  2.14e-02\n",
            "[Epoch    5/ 100] [Batch    4/   9] Loss:  2.18e-02\n",
            "[Epoch    5/ 100] [Batch    5/   9] Loss:  2.69e-02\n",
            "[Epoch    5/ 100] [Batch    6/   9] Loss:  2.47e-02\n",
            "[Epoch    5/ 100] [Batch    7/   9] Loss:  2.48e-02\n",
            "[Epoch    5/ 100] [Batch    8/   9] Loss:  2.30e-02\n",
            "[Epoch    5/ 100] [Batch    9/   9] Loss:  1.40e-02\n",
            "[Epoch    6/ 100] [Batch    1/   9] Loss:  1.68e-02\n",
            "[Epoch    6/ 100] [Batch    2/   9] Loss:  1.05e-02\n",
            "[Epoch    6/ 100] [Batch    3/   9] Loss:  7.55e-03\n",
            "[Epoch    6/ 100] [Batch    4/   9] Loss:  4.47e-03\n",
            "[Epoch    6/ 100] [Batch    5/   9] Loss:  3.96e-03\n",
            "[Epoch    6/ 100] [Batch    6/   9] Loss:  2.80e-03\n",
            "[Epoch    6/ 100] [Batch    7/   9] Loss:  2.57e-03\n",
            "[Epoch    6/ 100] [Batch    8/   9] Loss:  2.06e-03\n",
            "[Epoch    6/ 100] [Batch    9/   9] Loss:  3.05e-03\n",
            "[Epoch    7/ 100] [Batch    1/   9] Loss:  3.19e-03\n",
            "[Epoch    7/ 100] [Batch    2/   9] Loss:  3.92e-03\n",
            "[Epoch    7/ 100] [Batch    3/   9] Loss:  4.29e-03\n",
            "[Epoch    7/ 100] [Batch    4/   9] Loss:  5.66e-03\n",
            "[Epoch    7/ 100] [Batch    5/   9] Loss:  5.18e-03\n",
            "[Epoch    7/ 100] [Batch    6/   9] Loss:  6.39e-03\n",
            "[Epoch    7/ 100] [Batch    7/   9] Loss:  5.79e-03\n",
            "[Epoch    7/ 100] [Batch    8/   9] Loss:  4.33e-03\n",
            "[Epoch    7/ 100] [Batch    9/   9] Loss:  4.74e-03\n",
            "[Epoch    8/ 100] [Batch    1/   9] Loss:  3.41e-03\n",
            "[Epoch    8/ 100] [Batch    2/   9] Loss:  2.75e-03\n",
            "[Epoch    8/ 100] [Batch    3/   9] Loss:  2.07e-03\n",
            "[Epoch    8/ 100] [Batch    4/   9] Loss:  2.14e-03\n",
            "[Epoch    8/ 100] [Batch    5/   9] Loss:  1.83e-03\n",
            "[Epoch    8/ 100] [Batch    6/   9] Loss:  2.16e-03\n",
            "[Epoch    8/ 100] [Batch    7/   9] Loss:  2.20e-03\n",
            "[Epoch    8/ 100] [Batch    8/   9] Loss:  1.94e-03\n",
            "[Epoch    8/ 100] [Batch    9/   9] Loss:  1.67e-03\n",
            "[Epoch    9/ 100] [Batch    1/   9] Loss:  2.34e-03\n",
            "[Epoch    9/ 100] [Batch    2/   9] Loss:  1.99e-03\n",
            "[Epoch    9/ 100] [Batch    3/   9] Loss:  2.14e-03\n",
            "[Epoch    9/ 100] [Batch    4/   9] Loss:  2.02e-03\n",
            "[Epoch    9/ 100] [Batch    5/   9] Loss:  2.61e-03\n",
            "[Epoch    9/ 100] [Batch    6/   9] Loss:  2.48e-03\n",
            "[Epoch    9/ 100] [Batch    7/   9] Loss:  2.60e-03\n",
            "[Epoch    9/ 100] [Batch    8/   9] Loss:  2.22e-03\n",
            "[Epoch    9/ 100] [Batch    9/   9] Loss:  1.63e-03\n",
            "[Epoch   10/ 100] [Batch    1/   9] Loss:  1.91e-03\n",
            "[Epoch   10/ 100] [Batch    2/   9] Loss:  1.46e-03\n",
            "[Epoch   10/ 100] [Batch    3/   9] Loss:  1.42e-03\n",
            "[Epoch   10/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   10/ 100] [Batch    5/   9] Loss:  1.66e-03\n",
            "[Epoch   10/ 100] [Batch    6/   9] Loss:  2.03e-03\n",
            "[Epoch   10/ 100] [Batch    7/   9] Loss:  2.08e-03\n",
            "[Epoch   10/ 100] [Batch    8/   9] Loss:  1.59e-03\n",
            "[Epoch   10/ 100] [Batch    9/   9] Loss:  1.77e-03\n",
            "[Epoch   11/ 100] [Batch    1/   9] Loss:  1.67e-03\n",
            "[Epoch   11/ 100] [Batch    2/   9] Loss:  1.48e-03\n",
            "[Epoch   11/ 100] [Batch    3/   9] Loss:  1.42e-03\n",
            "[Epoch   11/ 100] [Batch    4/   9] Loss:  1.72e-03\n",
            "[Epoch   11/ 100] [Batch    5/   9] Loss:  1.66e-03\n",
            "[Epoch   11/ 100] [Batch    6/   9] Loss:  2.07e-03\n",
            "[Epoch   11/ 100] [Batch    7/   9] Loss:  2.04e-03\n",
            "[Epoch   11/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   11/ 100] [Batch    9/   9] Loss:  1.57e-03\n",
            "[Epoch   12/ 100] [Batch    1/   9] Loss:  1.56e-03\n",
            "[Epoch   12/ 100] [Batch    2/   9] Loss:  1.34e-03\n",
            "[Epoch   12/ 100] [Batch    3/   9] Loss:  1.36e-03\n",
            "[Epoch   12/ 100] [Batch    4/   9] Loss:  1.51e-03\n",
            "[Epoch   12/ 100] [Batch    5/   9] Loss:  1.68e-03\n",
            "[Epoch   12/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   12/ 100] [Batch    7/   9] Loss:  2.00e-03\n",
            "[Epoch   12/ 100] [Batch    8/   9] Loss:  1.63e-03\n",
            "[Epoch   12/ 100] [Batch    9/   9] Loss:  1.50e-03\n",
            "[Epoch   13/ 100] [Batch    1/   9] Loss:  1.60e-03\n",
            "[Epoch   13/ 100] [Batch    2/   9] Loss:  1.35e-03\n",
            "[Epoch   13/ 100] [Batch    3/   9] Loss:  1.38e-03\n",
            "[Epoch   13/ 100] [Batch    4/   9] Loss:  1.51e-03\n",
            "[Epoch   13/ 100] [Batch    5/   9] Loss:  1.64e-03\n",
            "[Epoch   13/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   13/ 100] [Batch    7/   9] Loss:  1.96e-03\n",
            "[Epoch   13/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   13/ 100] [Batch    9/   9] Loss:  1.53e-03\n",
            "[Epoch   14/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   14/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   14/ 100] [Batch    3/   9] Loss:  1.34e-03\n",
            "[Epoch   14/ 100] [Batch    4/   9] Loss:  1.55e-03\n",
            "[Epoch   14/ 100] [Batch    5/   9] Loss:  1.60e-03\n",
            "[Epoch   14/ 100] [Batch    6/   9] Loss:  1.94e-03\n",
            "[Epoch   14/ 100] [Batch    7/   9] Loss:  1.96e-03\n",
            "[Epoch   14/ 100] [Batch    8/   9] Loss:  1.53e-03\n",
            "[Epoch   14/ 100] [Batch    9/   9] Loss:  1.54e-03\n",
            "[Epoch   15/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   15/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   15/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   15/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   15/ 100] [Batch    5/   9] Loss:  1.62e-03\n",
            "[Epoch   15/ 100] [Batch    6/   9] Loss:  1.91e-03\n",
            "[Epoch   15/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   15/ 100] [Batch    8/   9] Loss:  1.55e-03\n",
            "[Epoch   15/ 100] [Batch    9/   9] Loss:  1.51e-03\n",
            "[Epoch   16/ 100] [Batch    1/   9] Loss:  1.55e-03\n",
            "[Epoch   16/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   16/ 100] [Batch    3/   9] Loss:  1.36e-03\n",
            "[Epoch   16/ 100] [Batch    4/   9] Loss:  1.52e-03\n",
            "[Epoch   16/ 100] [Batch    5/   9] Loss:  1.62e-03\n",
            "[Epoch   16/ 100] [Batch    6/   9] Loss:  1.91e-03\n",
            "[Epoch   16/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   16/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   16/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   17/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   17/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   17/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   17/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   17/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   17/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   17/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   17/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   17/ 100] [Batch    9/   9] Loss:  1.53e-03\n",
            "[Epoch   18/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   18/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   18/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   18/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   18/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   18/ 100] [Batch    6/   9] Loss:  1.91e-03\n",
            "[Epoch   18/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   18/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   18/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   19/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   19/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   19/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   19/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   19/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   19/ 100] [Batch    6/   9] Loss:  1.91e-03\n",
            "[Epoch   19/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   19/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   19/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   20/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   20/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   20/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   20/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   20/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   20/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   20/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   20/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   20/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   21/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   21/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   21/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   21/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   21/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   21/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   21/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   21/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   21/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   22/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   22/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   22/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   22/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   22/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   22/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   22/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   22/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   22/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   23/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   23/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   23/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   23/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   23/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   23/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   23/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   23/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   23/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   24/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   24/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   24/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   24/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   24/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   24/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   24/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   24/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   24/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   25/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   25/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   25/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   25/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   25/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   25/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   25/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   25/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   25/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   26/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   26/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   26/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   26/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   26/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   26/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   26/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   26/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   26/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   27/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   27/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   27/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   27/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   27/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   27/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   27/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   27/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   27/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   28/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   28/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   28/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   28/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   28/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   28/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   28/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   28/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   28/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   29/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   29/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   29/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   29/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   29/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   29/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   29/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   29/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   29/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   30/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   30/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   30/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   30/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   30/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   30/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   30/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   30/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   30/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   31/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   31/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   31/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   31/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   31/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   31/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   31/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   31/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   31/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   32/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   32/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   32/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   32/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   32/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   32/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   32/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   32/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   32/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   33/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   33/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   33/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   33/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   33/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   33/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   33/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   33/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   33/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   34/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   34/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   34/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   34/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   34/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   34/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   34/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   34/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   34/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   35/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   35/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   35/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   35/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   35/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   35/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   35/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   35/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   35/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   36/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   36/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   36/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   36/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   36/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   36/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   36/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   36/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   36/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   37/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   37/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   37/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   37/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   37/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   37/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   37/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   37/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   37/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   38/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   38/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   38/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   38/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   38/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   38/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   38/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   38/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   38/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   39/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   39/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   39/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   39/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   39/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   39/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   39/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   39/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   39/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   40/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   40/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   40/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   40/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   40/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   40/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   40/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   40/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   40/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   41/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   41/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   41/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   41/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   41/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   41/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   41/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   41/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   41/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   42/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   42/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   42/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   42/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   42/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   42/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   42/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   42/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   42/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   43/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   43/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   43/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   43/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   43/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   43/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   43/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   43/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   43/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   44/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   44/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   44/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   44/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   44/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   44/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   44/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   44/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   44/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   45/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   45/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   45/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   45/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   45/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   45/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   45/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   45/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   45/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   46/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   46/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   46/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   46/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   46/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   46/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   46/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   46/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   46/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   47/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   47/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   47/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   47/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   47/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   47/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   47/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   47/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   47/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   48/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   48/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   48/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   48/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   48/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   48/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   48/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   48/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   48/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   49/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   49/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   49/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   49/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   49/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   49/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   49/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   49/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   49/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   50/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   50/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   50/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   50/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   50/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   50/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   50/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   50/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   50/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   51/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   51/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   51/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   51/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   51/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   51/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   51/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   51/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   51/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   52/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   52/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   52/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   52/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   52/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   52/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   52/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   52/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   52/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   53/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   53/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   53/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   53/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   53/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   53/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   53/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   53/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   53/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   54/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   54/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   54/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   54/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   54/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   54/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   54/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   54/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   54/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   55/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   55/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   55/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   55/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   55/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   55/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   55/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   55/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   55/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   56/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   56/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   56/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   56/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   56/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   56/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   56/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   56/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   56/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   57/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   57/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   57/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   57/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   57/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   57/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   57/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   57/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   57/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   58/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   58/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   58/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   58/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   58/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   58/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   58/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   58/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   58/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   59/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   59/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   59/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   59/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   59/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   59/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   59/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   59/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   59/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   60/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   60/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   60/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   60/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   60/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   60/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   60/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   60/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   60/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   61/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   61/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   61/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   61/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   61/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   61/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   61/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   61/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   61/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   62/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   62/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   62/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   62/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   62/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   62/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   62/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   62/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   62/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   63/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   63/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   63/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   63/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   63/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   63/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   63/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   63/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   63/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   64/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   64/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   64/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   64/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   64/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   64/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   64/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   64/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   64/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   65/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   65/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   65/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   65/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   65/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   65/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   65/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   65/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   65/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   66/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   66/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   66/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   66/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   66/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   66/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   66/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   66/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   66/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   67/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   67/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   67/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   67/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   67/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   67/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   67/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   67/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   67/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   68/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   68/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   68/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   68/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   68/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   68/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   68/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   68/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   68/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   69/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   69/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   69/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   69/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   69/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   69/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   69/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   69/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   69/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   70/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   70/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   70/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   70/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   70/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   70/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   70/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   70/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   70/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   71/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   71/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   71/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   71/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   71/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   71/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   71/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   71/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   71/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   72/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   72/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   72/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   72/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   72/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   72/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   72/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   72/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   72/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   73/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   73/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   73/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   73/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   73/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   73/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   73/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   73/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   73/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   74/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   74/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   74/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   74/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   74/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   74/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   74/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   74/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   74/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   75/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   75/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   75/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   75/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   75/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   75/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   75/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   75/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   75/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   76/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   76/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   76/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   76/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   76/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   76/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   76/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   76/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   76/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   77/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   77/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   77/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   77/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   77/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   77/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   77/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   77/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   77/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   78/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   78/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   78/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   78/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   78/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   78/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   78/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   78/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   78/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   79/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   79/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   79/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   79/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   79/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   79/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   79/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   79/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   79/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   80/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   80/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   80/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   80/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   80/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   80/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   80/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   80/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   80/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   81/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   81/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   81/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   81/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   81/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   81/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   81/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   81/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   81/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   82/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   82/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   82/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   82/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   82/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   82/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   82/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   82/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   82/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   83/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   83/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   83/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   83/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   83/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   83/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   83/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   83/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   83/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   84/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   84/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   84/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   84/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   84/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   84/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   84/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   84/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   84/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   85/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   85/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   85/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   85/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   85/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   85/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   85/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   85/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   85/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   86/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   86/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   86/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   86/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   86/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   86/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   86/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   86/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   86/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   87/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   87/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   87/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   87/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   87/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   87/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   87/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   87/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   87/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   88/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   88/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   88/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   88/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   88/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   88/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   88/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   88/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   88/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   89/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   89/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   89/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   89/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   89/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   89/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   89/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   89/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   89/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   90/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   90/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   90/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   90/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   90/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   90/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   90/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   90/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   90/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   91/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   91/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   91/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   91/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   91/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   91/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   91/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   91/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   91/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   92/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   92/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   92/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   92/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   92/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   92/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   92/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   92/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   92/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   93/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   93/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   93/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   93/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   93/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   93/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   93/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   93/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   93/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   94/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   94/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   94/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   94/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   94/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   94/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   94/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   94/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   94/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   95/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   95/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   95/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   95/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   95/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   95/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   95/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   95/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   95/ 100] [Batch    9/   9] Loss:  1.52e-03\n",
            "[Epoch   96/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   96/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   96/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   96/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   96/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   96/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   96/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   96/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   96/ 100] [Batch    9/   9] Loss:  1.53e-03\n",
            "[Epoch   97/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   97/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   97/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   97/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   97/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   97/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   97/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   97/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   97/ 100] [Batch    9/   9] Loss:  1.53e-03\n",
            "[Epoch   98/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   98/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   98/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   98/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   98/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   98/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   98/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   98/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   98/ 100] [Batch    9/   9] Loss:  1.53e-03\n",
            "[Epoch   99/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch   99/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch   99/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch   99/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch   99/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch   99/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch   99/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch   99/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch   99/ 100] [Batch    9/   9] Loss:  1.53e-03\n",
            "[Epoch  100/ 100] [Batch    1/   9] Loss:  1.54e-03\n",
            "[Epoch  100/ 100] [Batch    2/   9] Loss:  1.33e-03\n",
            "[Epoch  100/ 100] [Batch    3/   9] Loss:  1.35e-03\n",
            "[Epoch  100/ 100] [Batch    4/   9] Loss:  1.53e-03\n",
            "[Epoch  100/ 100] [Batch    5/   9] Loss:  1.61e-03\n",
            "[Epoch  100/ 100] [Batch    6/   9] Loss:  1.92e-03\n",
            "[Epoch  100/ 100] [Batch    7/   9] Loss:  1.95e-03\n",
            "[Epoch  100/ 100] [Batch    8/   9] Loss:  1.54e-03\n",
            "[Epoch  100/ 100] [Batch    9/   9] Loss:  1.53e-03\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvn3BRnr7PI-",
        "outputId": "595d004c-ce0d-4cc6-da00-e2d62756a2d0"
      },
      "source": [
        "# Install required packages.\n",
        "!pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
        "!pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
        "!pip install -q git+https://github.com/rusty1s/pytorch_geometric.git\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 3.0 MB 4.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 3.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 376 kB 3.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 45 kB 3.4 MB/s \n",
            "\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0M9RwvszSTE5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOQCBMGO7c05"
      },
      "source": [
        "import torch_geometric\n",
        "from torch_geometric.datasets import Planetoid"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YL8OonQJ8pAB",
        "outputId": "4335126e-1ba6-4785-e86f-23ec5753425b"
      },
      "source": [
        "dataset = Planetoid(root = \"totorial1\", name = \"cora\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gH0jSwmO81k7",
        "outputId": "5beca229-6b37-45e4-8196-651df2b44efb"
      },
      "source": [
        "print(dataset)\n",
        "print(len(dataset))\n",
        "print(dataset.num_classes)\n",
        "print(dataset.num_node_features)\n",
        "print(dataset.num_edge_features)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejLXGteC-u0I",
        "outputId": "a0b9e762-78df-44b8-a335-5ccbc9631c83"
      },
      "source": [
        "print(dataset.data)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data(edge_index=[2, 10556], test_mask=[2708], train_mask=[2708], val_mask=[2708], x=[2708, 1433], y=[2708])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5ZzZN7c-yLo",
        "outputId": "2112486f-0b0a-4753-a6ad-9ef7590e78bd"
      },
      "source": [
        "print(dataset.data.edge_index.shape)\n",
        "print(dataset.data.x.shape)\n",
        "print(dataset.data.y.shape)\n",
        "print(dataset.data.train_mask)\n",
        "print(dataset.data.train_mask.shape)\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2708])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyixlxIgA3zl"
      },
      "source": [
        "import os.path as osp\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F \n",
        "from torch_geometric.nn import SAGEConv"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bd0fFN0TBThd"
      },
      "source": [
        "data = dataset[0]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KjiELIiCIkP"
      },
      "source": [
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.conv = SAGEConv(dataset.num_features, # 1433 \n",
        "                             dataset.num_classes, # 7\n",
        "                              aggr = \"max\")\n",
        "        \n",
        "    def forward(self):\n",
        "        x = self.conv(data.x, data.edge_index)\n",
        "        return F.log_softmax(x, dim = 1)\n",
        "\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e85pRcl8IWym",
        "outputId": "aa140ea6-1f48-4c3e-d07a-5ebf52216be6"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U07tQ4DiI2qh"
      },
      "source": [
        "model, data = Net().to(device), data.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01, weight_decay=5e-4)\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZst7C7cJiX4"
      },
      "source": [
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    F.nll_loss(model()[data.train_mask], data.y[data.train_mask]).backward()\n",
        "    optimizer.step()\n",
        "\n",
        "def test():\n",
        "    model.eval()\n",
        "    logits, accs = model(), []\n",
        "    for _, mask in data(\"train_mask\", \"val_mask\", \"test_mask\"):\n",
        "        pred = logits[mask].max(1)[1]\n",
        "        acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
        "        accs.append(acc)\n",
        "    return accs\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYoHHEW1Keph",
        "outputId": "924f4fe8-a7cd-42ea-d552-d18507e51932"
      },
      "source": [
        "best_val_acc = test_acc = 0\n",
        "for epoch in range(1,100):\n",
        "    train()\n",
        "    _, val_acc, tmp_test_acc = test()\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        test_acc = tmp_test_acc\n",
        "    log = 'Epoch: {:03d}, Val: {:.4f}, Test: {:.4f}'\n",
        "    \n",
        "    if epoch % 10 == 0:\n",
        "        print(log.format(epoch, best_val_acc, test_acc))\n",
        "\n",
        "        "
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0, 0.73, 0.724]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jDdqXAZSQlr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}